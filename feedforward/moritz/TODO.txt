TODO

1) BEFORE FINISHING CROSS VALIDATION

- evaluationsplotting zusammen mit changbin machen

- skript für kombinations-auswertungstabelle (levels 2,3 antizipieren) erstellen

- finally: detect (stuck in inprogress txt file) potentially failed runs via (error) logfile and resume them


2) SPEED UP TRAINING (OPTIONAL)
- try to put only non-complex models to adhara; add second run to each gpu with bs64 if possible.however it seems that simply the model complexity leads to large memory consumption (e.g. featuremaps 141 full mem while 23 only 6.5 GB (still more than half))


3) FINISH CROSS VALIDATION

- levels 2, 3 starten, nutze [und prüfe für diesen zweck] loadparams [heiner: lvl2+3 ab 83% oder 84% lvl1 val_wbac]

- optionally finally fine tuning featuremaps, droppoutrate, learningrate

4) FINAL EVALUATION

- finales modell trainieren und evaluieren

5) IN PARALLEL: INSTANT LABELS
- instant labels starten (gleich alle drei level)

- optionally finally fine tuning featuremaps, droppoutrate, learningrate

- optional: check dependence on output threshold

- finales instant modell trainieren und evaluieren

6) OPTIONALLY MORE VARIANTS
- blockbased und instant auch mit historysize 500 und 50 laufen lassen

7) FINALLY:
- put final result figs and h5 files (that can be used to replot) -- also incl final models  to github